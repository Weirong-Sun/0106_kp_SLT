# PHOENIX 数据集大小差异分析

## 问题描述

发现数据集中看到的数量与提取后的关键点数据数量不一致：

**数据集原始数量**（视频文件夹数）：
- train: 7096 个视频
- dev: 519 个视频
- test: 642 个视频

**提取后的关键点数据**（图像样本数）：
- train: 972 个样本
- dev: 1105 个样本
- test: 775 个样本

## 差异原因分析

### 原因 1: 使用了 `--max_samples_per_split` 参数（主要原因）

**实际情况**：
- `result_distributed.pkl` 中每个划分只包含 **10 个视频**的数据
- 说明在提取时使用了 `--max_samples_per_split 10` 参数
- 该参数限制了每个划分最多处理的视频数量

**对比数据**：

| 划分 | 数据集视频数 | 数据集图像数 | 提取视频数 | 提取图像数 | 覆盖率 |
|------|-------------|-------------|-----------|-----------|--------|
| **train** | 7,096 | 827,354 | 10 | 972 | **0.14%** |
| **dev** | 519 | 55,775 | 10 | 1,105 | **1.93%** |
| **test** | 642 | 64,627 | 10 | 775 | **1.56%** |
| **总计** | **8,257** | **947,756** | **30** | **2,852** | **0.30%** |

### 原因 2: 单位不同（次要）

- **数据集数量**：指的是**视频文件夹数量**（每个视频包含多个图像帧）
- **提取结果**：指的是**图像样本数量**（每个图像提取一次关键点）

例如：
- train 数据集有 7,096 个视频
- 平均每个视频约 116.6 个图像
- 所以总共有约 827,354 个图像
- 但提取时只处理了前 10 个视频
- 这 10 个视频共有 972 个图像

## 验证方法

### 方法 1: 检查数据集实际大小

```bash
python analyze_dataset_size.py --result_pkl result_distributed.pkl
```

这会显示：
- 数据集的实际大小（视频数和图像数）
- 提取结果的对比
- 覆盖率分析
- 建议的完整提取命令

### 方法 2: 手动检查

```bash
# 检查数据集中的视频数量
find /data/phd/wsun/datasets/PHOENIX-2014-T-release-v3/PHOENIX-2014-T/features/fullFrame-210x260px/train -type d -mindepth 1 | wc -l

# 检查提取结果中的视频数量
python -c "import pickle; d=pickle.load(open('result_distributed.pkl','rb')); print('Train videos:', len(set(d['train']['video_ids'])))"
```

## 解决方案

### 完整提取所有数据

要提取**完整数据集**的所有关键点，需要**不使用** `--max_samples_per_split` 参数：

```bash
# 完整提取所有数据（推荐）
python data/extract_phoenix_keypoints_distributed.py \
    --dataset_path /data/phd/wsun/datasets/PHOENIX-2014-T-release-v3/PHOENIX-2014-T \
    --output_path phoenix_keypoints_full.pkl \
    --num_workers 4

# 注意：不使用 --max_samples_per_split 参数！
```

### 处理时间估算

假设处理速度：
- 单进程：约 1 图像/秒
- 4进程并行：约 3-4 图像/秒

**总图像数**: 947,756 个

**估算时间**：
- 4进程：947,756 / 3 = 约 316,000 秒 ≈ **88 小时** ≈ **3.7 天**

**建议**：
- 可以在后台运行
- 使用 `nohup` 或 `screen`/`tmux` 保持会话
- 定期检查进度

### 分批处理（可选）

如果担心长时间运行，可以分批处理：

```bash
# 只处理训练集（最大，约 70 小时）
python data/extract_phoenix_keypoints_distributed.py \
    --dataset_path /data/phd/wsun/datasets/PHOENIX-2014-T-release-v3/PHOENIX-2014-T \
    --output_path phoenix_keypoints_train.pkl \
    --splits train \
    --num_workers 4

# 然后处理验证集和测试集
python data/extract_phoenix_keypoints_distributed.py \
    --dataset_path /data/phd/wsun/datasets/PHOENIX-2014-T-release-v3/PHOENIX-2014-T \
    --output_path phoenix_keypoints_dev_test.pkl \
    --splits dev test \
    --num_workers 4
```

## 当前结果说明

### 当前提取结果（result_distributed.pkl）

- **用途**: 测试/验证用
- **覆盖**: 每个划分前 10 个视频
- **样本数**: 2,852 个图像
- **状态**: ✅ 处理完成，结果正确
- **适用**: 用于测试流程、验证代码、快速验证

### 完整数据集

- **视频数**: 8,257 个
- **图像数**: 947,756 个
- **状态**: ⚠️ 未完全提取
- **建议**: 需要完整提取才能用于正式训练

## 检查提取进度

### 方法 1: 使用进度检查脚本

```bash
python check_extraction_progress.py phoenix_keypoints_full.pkl
```

### 方法 2: 手动检查文件大小

```bash
# 监控文件大小变化
watch -n 60 'ls -lh phoenix_keypoints_full.pkl 2>/dev/null || echo "文件不存在"'
```

### 方法 3: 检查日志

```bash
# 如果使用 nohup 运行
tail -f nohup.out

# 或重定向到日志文件
python data/extract_phoenix_keypoints_distributed.py ... > extraction.log 2>&1
tail -f extraction.log
```

## 数据量说明

### 数据集完整统计

| 项目 | 数量 |
|------|------|
| **总视频数** | 8,257 |
| **总图像数** | 947,756 |
| **平均每个视频** | ~115 个图像 |
| **完整提取后文件大小估算** | ~1.5-2 GB |

### 当前提取结果统计

| 项目 | 数量 | 占比 |
|------|------|------|
| **处理视频数** | 30 | 0.36% |
| **处理图像数** | 2,852 | 0.30% |
| **文件大小** | 5.26 MB | - |

## 完整提取命令（后台运行）

```bash
# 使用 nohup 在后台运行
nohup python data/extract_phoenix_keypoints_distributed.py \
    --dataset_path /data/phd/wsun/datasets/PHOENIX-2014-T-release-v3/PHOENIX-2014-T \
    --output_path phoenix_keypoints_full.pkl \
    --num_workers 4 \
    > extraction.log 2>&1 &

# 查看进程
ps aux | grep extract_phoenix_keypoints_distributed

# 查看日志
tail -f extraction.log
```

## 相关工具

- **`analyze_dataset_size.py`**: 分析数据集大小和提取结果对比
- **`check_extraction_progress.py`**: 检查提取进度
- **`view_keypoints.py`**: 查看提取结果

## 建议

1. **当前结果**: `result_distributed.pkl` 是测试数据，可用于验证流程
2. **完整提取**: 如果需要完整数据集，运行完整提取命令（注意：需要较长时间）
3. **进度监控**: 定期检查提取进度
4. **资源考虑**: 确保有足够的磁盘空间（约 2 GB）

---

**文档创建时间**: 2024年
**问题**: 数据量差异分析
**原因**: 使用了 `--max_samples_per_split 10` 参数


